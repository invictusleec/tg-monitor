from telethon.sync import TelegramClient
from telethon.sessions import StringSession
from sqlalchemy.orm import Session
from sqlalchemy import or_, cast, String
from model import Message, engine, ChannelRule, create_tables
from config import settings
import datetime
import re
import sys

# ------------------------ è§„åˆ™ç¼“å­˜ä¸åˆ¤æ–­ ------------------------
RULES_CACHE = {}

def load_rules_cache():
    global RULES_CACHE
    try:
        with Session(engine) as session:
            rules = session.query(ChannelRule).filter_by(enabled=True).all()
            RULES_CACHE = {
                r.channel: {
                    'exclude_netdisks': set((r.exclude_netdisks or [])),
                    'exclude_keywords': [kw.lower() for kw in (r.exclude_keywords or []) if kw],
                    'exclude_tags': set((r.exclude_tags or [])),
                }
                for r in rules
            }
            print(f"âš™ï¸ å·²åŠ è½½è§„åˆ™ {len(RULES_CACHE)} æ¡")
    except Exception as e:
        print(f"âš ï¸ åŠ è½½è§„åˆ™å¤±è´¥: {e}")

def should_drop_by_rules(channel: str, parsed: dict) -> bool:
    if not channel:
        return False
    rule = RULES_CACHE.get(channel)
    if not rule:
        return False
    # 1) ç½‘ç›˜ç±»å‹å‘½ä¸­
    links = parsed.get('links') or {}
    if links and rule['exclude_netdisks'] and (set(links.keys()) & rule['exclude_netdisks']):
        return True
    # 2) å…³é”®è¯å‘½ä¸­ï¼ˆæ ‡é¢˜/æè¿°ï¼‰
    kws = rule['exclude_keywords']
    if kws:
        title = (parsed.get('title') or '').lower()
        desc = (parsed.get('description') or '').lower()
        for kw in kws:
            if kw and (kw in title or kw in desc):
                return True
    # 3) æ ‡ç­¾å‘½ä¸­
    tags = set(parsed.get('tags') or [])
    if tags and rule['exclude_tags'] and (tags & rule['exclude_tags']):
        return True
    return False

# ------------------------ æ–‡æœ¬è§£æï¼ˆä¸ monitor.py ä¿æŒä¸€è‡´ï¼‰ ------------------------

def parse_message(text: str):
    lines = text.split('\n')
    title = ''
    description = ''
    links = {}
    tags = []
    source = ''
    channel = ''
    group = ''
    bot = ''
    current_section = None
    desc_lines = []

    netdisk_map = [
        (['quark', 'å¤¸å…‹'], 'å¤¸å…‹ç½‘ç›˜'),
        (['aliyundrive', 'aliyun', 'é˜¿é‡Œ', 'alipan'], 'é˜¿é‡Œäº‘ç›˜'),
        (['baidu', 'pan.baidu'], 'ç™¾åº¦ç½‘ç›˜'),
        (['115.com', '115ç½‘ç›˜', '115pan'], '115ç½‘ç›˜'),
        (['cloud.189', 'å¤©ç¿¼', '189.cn'], 'å¤©ç¿¼äº‘ç›˜'),
        (['123pan', '123.yun'], '123äº‘ç›˜'),
        (['ucdisk', 'ucç½‘ç›˜', 'ucloud', 'drive.uc.cn'], 'UCç½‘ç›˜'),
        (['xunlei', 'thunder', 'è¿…é›·'], 'è¿…é›·'),
    ]

    if lines and lines[0].strip():
        if lines[0].startswith('åç§°ï¼š'):
            title = lines[0].replace('åç§°ï¼š', '').strip()
        else:
            title = lines[0].strip()

    for idx, line in enumerate(lines[1:] if title else lines):
        line = line.strip()
        if not line:
            continue
        if line.startswith('ğŸ· æ ‡ç­¾ï¼š') or line.startswith('æ ‡ç­¾ï¼š'):
            tags.extend([tag.strip('#') for tag in line.replace('ğŸ· æ ‡ç­¾ï¼š', '').replace('æ ‡ç­¾ï¼š', '').split() if tag.strip('#')])
            continue
        if line.startswith('æè¿°ï¼š'):
            current_section = 'description'
            desc_lines.append(line.replace('æè¿°ï¼š', '').strip())
        elif line.startswith('é“¾æ¥ï¼š'):
            current_section = 'links'
            url = line.replace('é“¾æ¥ï¼š', '').strip()
            if not url:
                continue
            found = False
            for keys, name in netdisk_map:
                if any(k in url.lower() for k in keys):
                    links[name] = url
                    found = True
                    break
            if not found:
                links['å…¶ä»–'] = url
        elif line.startswith('ğŸ‰ æ¥è‡ªï¼š'):
            source = line.replace('ğŸ‰ æ¥è‡ªï¼š', '').strip()
        elif line.startswith('ğŸ“¢ é¢‘é“ï¼š'):
            channel = line.replace('ğŸ“¢ é¢‘é“ï¼š', '').strip()
        elif line.startswith('ğŸ‘¥ ç¾¤ç»„ï¼š'):
            group = line.replace('ğŸ‘¥ ç¾¤ç»„ï¼š', '').strip()
        elif line.startswith('ğŸ¤– æŠ•ç¨¿ï¼š'):
            bot = line.replace('ğŸ¤– æŠ•ç¨¿ï¼š', '').strip()
        elif current_section == 'description':
            desc_lines.append(line)
        else:
            desc_lines.append(line)

    desc_text = '\n'.join(desc_lines)
    pattern = re.compile(r'([\u4e00-\u9fa5A-Za-z0-9#]+)[ï¼š:](https?://[^\s]+)')
    matches = pattern.findall(desc_text)
    for key, url in matches:
        found = False
        for keys, name in netdisk_map:
            if any(k in url.lower() or k in key for k in keys):
                links[name] = url
                found = True
                break
        if not found:
            links[key.strip()] = url
    desc_text = pattern.sub('', desc_text)

    url_pattern = re.compile(r'(https?://[^\s]+)')
    for url in url_pattern.findall(desc_text):
        found = False
        for keys, name in netdisk_map:
            if any(k in url.lower() for k in keys):
                links[name] = url
                found = True
                break
        if not found:
            links['å…¶ä»–'] = url
    desc_text = url_pattern.sub('', desc_text)

    tag_pattern = re.compile(r'#([\u4e00-\u9fa5A-Za-z0-9_]+)')
    found_tags = tag_pattern.findall(desc_text)
    if found_tags:
        tags.extend(found_tags)
        desc_text = tag_pattern.sub('', desc_text)

    tags = list(set(tags))
    netdisk_names = ['å¤¸å…‹', 'è¿…é›·', 'ç™¾åº¦', 'UC', 'é˜¿é‡Œ', 'å¤©ç¿¼', '115', '123äº‘ç›˜']
    netdisk_name_pattern = re.compile(r'(' + '|'.join(netdisk_names) + r')')
    desc_text = netdisk_name_pattern.sub('', desc_text)

    desc_lines_final = [line for line in desc_text.strip().split('\n') if line.strip() and not re.fullmatch(r'[.ã€‚Â·ã€,ï¼Œ-]+', line.strip())]
    description = '\n'.join(desc_lines_final)

    return {
        'title': title,
        'description': description,
        'links': links,
        'tags': tags,
        'source': source,
        'channel': channel,
        'group_name': group,
        'bot': bot
    }

# ------------------------ è¦†ç›–å†™å…¥ï¼ˆä»¥é“¾æ¥ä¸ºå”¯ä¸€ï¼‰ ------------------------

def upsert_message_by_links(session: Session, parsed_data: dict, timestamp: datetime.datetime):
    links = parsed_data.get('links') or {}
    urls = set(links.values()) if links else set()

    if urls:
        like_filters = [cast(Message.links, String).like(f"%{u}%") for u in urls]
        candidates = session.query(Message).filter(
            Message.links.isnot(None),
            or_(*like_filters)
        ).order_by(Message.timestamp.desc()).all()

        target = None
        for msg in candidates:
            try:
                msg_links = (msg.links or {}).values()
                if any(u == v for u in urls for v in msg_links):
                    target = msg
                    break
            except Exception:
                continue

        if target:
            target.timestamp = timestamp
            target.title = parsed_data.get('title')
            target.description = parsed_data.get('description')
            target.links = parsed_data.get('links')
            target.tags = parsed_data.get('tags')
            target.source = parsed_data.get('source')
            target.channel = parsed_data.get('channel')
            target.group_name = parsed_data.get('group_name')
            target.bot = parsed_data.get('bot')
            session.commit()
            print(f"â™»ï¸ å·²è¦†ç›–æ›´æ–°ç°æœ‰æ¶ˆæ¯(id={target.id})ï¼ŒæŒ‰é“¾æ¥å»é‡")
            return "updated"

    new_message = Message(timestamp=timestamp, **parsed_data)
    session.add(new_message)
    session.commit()
    print("âœ… æ–°æ¶ˆæ¯å·²ä¿å­˜ï¼ˆæ— é‡å¤é“¾æ¥ï¼‰")
    return "inserted"

# ------------------------ ä¸»é€»è¾‘ï¼šå›æº¯å¯¼å…¥ ------------------------

def main():
    create_tables()
    load_rules_cache()

    api_id = settings.TELEGRAM_API_ID
    api_hash = settings.TELEGRAM_API_HASH
    string_session = (settings.STRING_SESSION.strip() if getattr(settings, 'STRING_SESSION', None) else None)

    if not string_session:
        raise RuntimeError("æœªé…ç½® STRING_SESSIONï¼Œè¯·åœ¨ .env ä¸­è®¾ç½®åå†è¿è¡Œæœ¬è„šæœ¬")

    target_channel = 'bsbdbfjfjff'
    print(f"âª å¼€å§‹å›æº¯å¹¶å¯¼å…¥é¢‘é“ @{target_channel} çš„å†å²æ¶ˆæ¯ï¼ˆæŒ‰å½“å‰è§„åˆ™ï¼Œä»…å¯¼å…¥å«ç½‘ç›˜é“¾æ¥çš„æ¶ˆæ¯ï¼›é“¾æ¥å”¯ä¸€è¦†ç›–ï¼‰")

    inserted, updated, skipped_non_netdisk = 0, 0, 0

    with TelegramClient(StringSession(string_session), api_id, api_hash) as client:
        for message in client.iter_messages(target_channel, reverse=True):
            # ä»…å¤„ç†æœ‰æ–‡æœ¬çš„æ¶ˆæ¯
            text = getattr(message, 'message', None) or getattr(message, 'raw_text', None) or ''
            if not text.strip():
                continue

            parsed = parse_message(text)
            parsed['channel'] = target_channel

            # è§„åˆ™è¿‡æ»¤
            if should_drop_by_rules(target_channel, parsed):
                continue

            # ä»…å¯¼å…¥â€œå…³äºç½‘ç›˜â€çš„æ¶ˆæ¯ï¼ˆå¿…é¡»åŒ…å« linksï¼‰
            if not parsed.get('links'):
                skipped_non_netdisk += 1
                continue

            ts = getattr(message, 'date', None) or datetime.datetime.utcnow()
            with Session(engine) as session:
                r = upsert_message_by_links(session, parsed, ts)
                if r == 'updated':
                    updated += 1
                else:
                    inserted += 1

    print(f"âœ… å¯¼å…¥å®Œæˆï¼šæ–°å¢ {inserted} æ¡ï¼Œè¦†ç›–æ›´æ–° {updated} æ¡ï¼Œè·³è¿‡éç½‘ç›˜ {skipped_non_netdisk} æ¡")


if __name__ == '__main__':
    main()